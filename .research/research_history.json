{
  "base_queries": [
    "diffusion model"
  ],
  "base_github_url": "https://github.com/coderpiaobozhe/classifier-free-diffusion-guidance-Pytorch",
  "base_method_text": {
    "arxiv_id": "2312.07586v5",
    "arxiv_url": "http://arxiv.org/abs/2312.07586v5",
    "title": "Characteristic Guidance: Non-linear Correction for Diffusion Model at\n  Large Guidance Scale",
    "authors": [
      "Candi Zheng",
      "Yuan Lan"
    ],
    "published_date": "2023-12-11T02:40:40Z",
    "journal": "",
    "doi": "",
    "summary": "Popular guidance for denoising diffusion probabilistic model (DDPM) linearly\ncombines distinct conditional models together to provide enhanced control over\nsamples. However, this approach overlooks nonlinear effects that become\nsignificant when guidance scale is large. To address this issue, we propose\ncharacteristic guidance, a guidance method that provides first-principle\nnon-linear correction for classifier-free guidance. Such correction forces the\nguided DDPMs to respect the Fokker-Planck (FP) equation of diffusion process,\nin a way that is training-free and compatible with existing sampling methods.\nExperiments show that characteristic guidance enhances semantic characteristics\nof prompts and mitigate irregularities in image generation, proving effective\nin diverse applications ranging from simulating magnet phase transitions to\nlatent space sampling.",
    "github_url": "https://github.com/coderpiaobozhe/classifier-free-diffusion-guidance-Pytorch",
    "main_contributions": "The paper introduces Characteristic Guidance, a novel non-linear correction method for classifier-free guided Denoising Diffusion Probabilistic Models (DDPMs) that addresses the irregularities arising from large guidance scales. The method enforces adherence to the Fokker-Planck equation, enhancing semantic characteristics and mitigating image generation artifacts.",
    "methodology": "Characteristic guidance corrects classifier-free guidance by incorporating a non-linear correction term (∆x) derived from the Fokker-Planck equation using the method of characteristics and a harmonic ansatz. This involves iteratively solving a fixed-point equation to determine ∆x, using accelerated fixed-point iteration algorithms and projection operators for regularization and faster convergence.",
    "experimental_setup": "The method was evaluated on conditional Gaussian distributions, mixtures of Gaussians, simulations of magnet phase transitions (Landau-Ginzburg model), and image generation tasks using CIFAR-10, ImageNet 256 (with latent diffusion models), and Stable Diffusion. Evaluation metrics included KL divergence, Negative Log-Likelihood (NLL), Frechet Inception Distance (FID), Inception Score (IS), and visual inspection.",
    "limitations": "The effectiveness of FID as an evaluation metric is compromised due to the discrepancy between target conditional probabilities and marginal probabilities. The iterative computation of the non-linear correction term can be slow, and the method's performance relies on the harmonic ansatz, which may not hold in all scenarios.",
    "future_research_directions": "Future research directions include exploring advanced regularization techniques to enhance the convergence rate of the iterative computation and investigating more appropriate evaluation metrics that account for the goals of guided DDPMs. It also includes exploration on how to relax the harmonic ansatz."
  },
  "add_queries": [
    "vision"
  ],
  "generated_queries": [
    "diffusion guidance",
    "nonlinear correction",
    "fokker planck",
    "fixed point",
    "harmonic ansatz"
  ],
  "add_github_urls": [
    "https://github.com/openai/improved-diffusion"
  ],
  "add_method_texts": [
    {
      "arxiv_id": "2310.18762v1",
      "arxiv_url": "http://arxiv.org/abs/2310.18762v1",
      "title": "Purify++: Improving Diffusion-Purification with Advanced Diffusion\n  Models and Control of Randomness",
      "authors": [
        "Boya Zhang",
        "Weijian Luo",
        "Zhihua Zhang"
      ],
      "published_date": "2023-10-28T17:18:38Z",
      "journal": "",
      "doi": "",
      "summary": "Adversarial attacks can mislead neural network classifiers. The defense\nagainst adversarial attacks is important for AI safety. Adversarial\npurification is a family of approaches that defend adversarial attacks with\nsuitable pre-processing. Diffusion models have been shown to be effective for\nadversarial purification. Despite their success, many aspects of diffusion\npurification still remain unexplored. In this paper, we investigate and improve\nupon three limiting designs of diffusion purification: the use of an improved\ndiffusion model, advanced numerical simulation techniques, and optimal control\nof randomness. Based on our findings, we propose Purify++, a new diffusion\npurification algorithm that is now the state-of-the-art purification method\nagainst several adversarial attacks. Our work presents a systematic exploration\nof the limits of diffusion purification methods.",
      "github_url": "https://github.com/openai/improved-diffusion",
      "main_contributions": "The paper introduces Purify++, a novel diffusion purification algorithm that achieves state-of-the-art adversarial robustness. It improves upon existing diffusion purification methods by optimizing three key aspects: the diffusion model itself, the numerical simulation techniques used, and the control of randomness during purification. The research systematically explores the limits of diffusion purification, demonstrating significant performance gains against various adversarial attacks.",
      "methodology": "Purify++ employs an improved diffusion model (EDM, a generalization of VE diffusion), efficient simulation of purification SDE using Heun's method, and optimal control of randomness by combining purification ODE and Langevin dynamics. The strength of randomness is controlled by a mixing coefficient λ to enhance adversarial robustness.",
      "experimental_setup": "The method is evaluated on the CIFAR10 and MNIST datasets using various adversarial attacks, including black-box attacks (Square Attack, SPSA), gray-box attacks (PGD), and strong adaptive attacks (BPDA+EOT). Performance is measured using standard and robust accuracy, comparing against other adversarial defense methods and conducting ablation studies to assess the contribution of each component.",
      "limitations": "The evaluation of the BPDA+EOT attack is performed on a subset of the test set due to the high computational cost. Some experimental details and ablation study results are deferred to the appendix due to space limitations.",
      "future_research_directions": "The paper suggests further developments in diffusion-based purification methods, implying exploration of new diffusion models, advanced simulation techniques, and adaptive control of randomness to further enhance adversarial robustness and computational efficiency."
    }
  ],
  "base_experimental_code": "The repository provides code for training and sampling from a diffusion model with classifier-free guidance. However, there is no explicit code implementing 'Characteristic Guidance', the non-linear correction method at the core of the paper. The diffusion.py file contains the implementation of Gaussian Diffusion, including forward and reverse processes, and the training loss. The sample.py and train.py files contain the sampling and training loops respectively. The unet.py defines the UNet architecture used as the conditional generator.",
  "base_experimental_info": "The experimental setup involves training a UNet model on CIFAR-10 dataset using the code provided. Key parameters include: Timesteps (T=1000), Guidance scale (w=1.8), Variance parameter (v=0.3), Learning rate (lr=2e-4), Batch size (batchsize=256), Number of classes (clsnnum=10), Sampling steps for DDIM (num_steps=50), Eta for DDIM variance (eta=0.0). The code supports distributed training. Evaluation is performed by visual inspection of generated samples, and quantitative metrics like FID are calculated."
}