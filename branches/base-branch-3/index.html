
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Research Paper</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
      margin: 2rem auto;
      max-width: 800px;
      padding: 0 1rem;
      line-height: 1.6;
      color: #333;
      background-color: #fff;
    }
    h2.paper-title {
      font-size: 1.8em;
      font-weight: 700;
      text-align: center;
      margin-bottom: 0.5em;
      border-bottom: none;
    }
    h2 {
      border-bottom: 2px solid #ddd;
      padding-bottom: 0.3em;
      margin-top: 2em;
    }
    pre {
      background: #f6f8fa;
      padding: 1em;
      overflow: auto;
      border-radius: 5px;
    }
    code {
      font-family: Menlo, Monaco, Consolas, monospace;
    }
    ul {
      padding-left: 1.5em;
    }
    figure {
      text-align: center;
      margin: 1.5em 0;
      background: none !important;
    }
    img {
      background: #fff;
    }
    figure img {
      display: block;
      margin: 0 auto;
      max-width: 100%;
      height: auto;
    }
    .img-pair .pair {
      display: flex;
      justify-content: space-between;
    }
    .img-pair img {
      max-width: 48%;
      height: auto;
    }
    figcaption {
      font-size: 0.9em;
      color: #666;
    }
  </style>
</head>
<body>
<h2 class="paper-title">Adaptive Characteristic Simulation for Non-Linear Correction in Guided Diffusion</h2>

<section>
  <h2>Abstract</h2>
  <p>We introduce Adaptive Characteristic Simulation (ACS), a novel approach for improving classifier-free guided Denoising Diffusion Probabilistic Models (DDPMs) under large guidance scales. Whereas prior work often relies on fixed-point iterations and harmonic assumptions to handle high-scale imbalances, ACS replaces this approach with a multi-stage numerical scheme driven by local error estimates.</p>
  <p>Specifically, ACS adapts both step size and random perturbation intensity in an SDE-based framework, providing robust performance in high-curvature regions where purely linear corrections fail. To validate its effectiveness, we conduct three experiments: (1) a synthetic ODE integration task, highlighting the efficiency of adaptive steps; (2) a controlled noise injection scenario, showing that dynamically tuned random perturbations improve stability; and (3) a toy end-to-end diffusion-based sampling experiment comparing ACS with standard guidance methods in terms of convergence quality and runtime.</p>
  <p>Results consistently indicate reduced computational burden, better stability, and enhanced control over sample trajectories, thus demonstrating the value of ACS for non-linear guidance in complex diffusion problems.</p>
</section>

<section>
  <h2>Introduction</h2>
  <p>Denoising Diffusion Probabilistic Models (DDPMs) have established themselves as a powerful class of generative models, notably for image synthesis tasks such as unconditional and conditional generation. In classifier-free guidance, we often blend conditional and unconditional score estimates to adjust semantic fidelity, leveraging a guidance weight to balance these two components. While this technique proves effective for moderate guidance scales, pushing that scale higher can significantly amplify nonlinear drifts, producing unwieldy or divergent sampling behavior.</p>
  <p>Addressing strong nonlinear effects poses a challenge. Traditional linear procedures assume that the conditional and unconditional signals combine in a straightforward manner, which becomes inadequate under high curvature or out-of-distribution samples. Motivated by these constraints, we propose Adaptive Characteristic Simulation (ACS) to more accurately track and correct the sampling trajectory when large guidance scales are in play.</p>
  <p>The essential roadblock is that iterative corrections for high guidance scales can converge very slowly or fail to capture subtle drifts fully. Our strategy is to incorporate advanced numerical practices from the domain of stiff ODE and SDE solvers, where variable step size and dynamic noise modulation are routinely used to handle quickly changing gradients. In ACS, we take a staged approach, splitting the diffusion trajectory into segments, each governed by local error estimates that help us decide how to adapt step sizes and noise intensities.</p>
  <p>Why is this hard? Large guidance scales break assumptions of linearity. Small mismatches in the conditional score can be greatly magnified, and the fixed-step iteration commonly used in naive implementations does not sufficiently accommodate rapid deviations. At the same time, too much randomness in high-curvature regions can cause instability, prompting the need for tight control of stochastic terms.</p>
  <ul>
    <li><strong>Multi-stage SDE-based solver:</strong> We propose abandoning the harmonic ansatz by making data-driven decisions for each segment of the diffusion trajectory.</li>
    <li><strong>Adaptive step size scheduling:</strong> We manage local curvature by reducing iteration counts where possible and increasing resolution where needed.</li>
    <li><strong>Controlled random perturbations:</strong> We introduce a method to dynamically tune noise levels, improving stability against unexpected surges in gradient magnitude.</li>
    <li><strong>Experimental validation:</strong> We demonstrate ACS through experiments ranging from synthetic ODE scenarios to a simplified UNet-based simulation that underscores its improvements in efficiency, stability, and sample fidelity.</li>
  </ul>
  <p>Looking ahead, our approach opens up possibilities for integrating more sophisticated regularization techniques, exploring alternative error estimators, and applying ACS to full-scale datasets or real-world tasks. In the following sections, we detail relevant literature, outline necessary background concepts, present our proposed method, then describe and evaluate these contributions experimentally.</p>
</section>

<section>
  <h2>Related Work</h2>
  <p>Classifier-free guidance was introduced as an elegant solution to balancing conditional semantic information with an unconditional baseline for diffusion sampling. While linear interpolations of conditional and unconditional signals work well for moderate scales, larger scales frequently lead to artifacts and, at times, collapse. Several researchers have attempted to mitigate these instabilities through partial or heuristic nonlinear reweighting mechanisms, but the overall reliance on linear assumptions remains the norm.</p>
  <p>Outside of guided diffusion itself, the numerical modeling community has long explored adaptive solvers for stiff or highly nonlinear ODEs and SDEs. Variable time-stepping and step size scheduling are central ideas here, reducing computation where the system is smooth and providing fine-grained resolution in regions of high curvature. Similarly, mixing deterministic integration with adjustable noise inputs is not a new technique in the realm of stochastic processes. For instance, Purify++ introduced advanced ODE/SDE techniques to handle dynamic equilibria.</p>
  <p>However, convergence of large-scale classifier-free guidance specifically can fall outside the typical design constraints of classical numerical solvers. The ad hoc nature of linear gradient coupling may fail to incorporate the full distributional context. Our approach, ACS, draws inspiration from these well-tested numerical methods but customizes them for guided diffusion by coupling local error estimation with strategic noise adjustments in each stage of the diffusion path. In so doing, we are able to address more extreme guidance weights without either overly simplifying or re-engineering domain-specific expansions. Thus, ACS bridges a gap between purely empirical or heuristic corrections and a principled, numerically grounded methodology.</p>
</section>

<section>
  <h2>Background</h2>
  <p>Classifier-free guidance is formalized by training one neural network on both conditional and unconditional objectives. For a sample x at an intermediate diffusion step, the unconditional score is s<sub>u</sub>, and the conditional score is s<sub>c</sub>. The typical linear combination is s<sub>u</sub> + w(s<sub>c</sub> – s<sub>u</sub>), where w is the guidance weight. When w is small, fluctuations in s<sub>c</sub> are adequately approximated. But as w grows, we enter a regime that can deviate significantly from the original distribution assumptions, giving rise to large sample drifts.</p>
  <p>Characteristic guidance is one attempt to handle these drifts systematically by invoking the Fokker–Planck equation, deriving a correction term that ensures consistency with diffusion dynamics. This correction can be computed via a harmonic ansatz and fixed-point iteration. But in practice, large w can make those iterations computationally burdensome, and the harmonic assumption may not match the actual geometry of the data manifold.</p>
  <p>From a numerical perspective, many stiff or rapidly varying systems can benefit from adaptive step size integrators, which use local error estimations to dynamically select the next step. For SDEs, the notion of controlling random perturbations is similarly well-known: if the system is very sensitive, one may want to reduce noise; if it is stable, a wider range of stochastic exploration can be tolerated. Tying these ideas back to guided diffusion, we see that local error metrics can guide both the deterministic correction and the level of stochastic injection.</p>
  <p>Our proposed Adaptive Characteristic Simulation (ACS) merges these insights: it discards a precise closed-form correction like the harmonic ansatz in favor of a direct, stage-wise numerical integration that is free to adjust stepsizes and noise intensities on the fly. This approach remains faithful to the underlying diffusion structure while being agile enough to respond to large-scale guidance scenarios without repeated re-derivations of specialized expansions or slow-to-converge fixed-point loops.</p>
</section>

<section>
  <h2>Method</h2>
  <p>Adaptive Characteristic Simulation (ACS) tackles large guidance scales by treating the classifier-free updated diffusion as an SDE whose drift and noise levels can be tuned adaptively. The main algorithmic components are detailed below:</p>
  <p><strong>Adaptive Non-linear Simulation:</strong> Instead of employing a fixed-point correction, ACS reformulates the guidance step as an iterative SDE integration: dx = F(x) dt + G(x) dW, where F(x) is the drift derived from the conditional/unconditional score difference, and G(x) is a noise term controlling stochastic exploration. By integrating this SDE in stages, ACS naturally accommodates nonlinearities that arise from large w.</p>
  <p><strong>Staged Step Size Scheduling:</strong> Each integration step compares the predicted solution at one full step with that from two half steps, generating a local error estimate. If the error exceeds a threshold, the algorithm reduces the step size to gain accuracy. Conversely, if the error is well below the threshold, the step size is increased to save on compute. This approach, largely inspired by adaptive ODE solvers, ensures that ACS devotes computational resources precisely where the diffusion trajectory is most complex.</p>
  <p><strong>Controlled Random Perturbations:</strong> Classifier-free guidance can introduce pathologies when high guidance amplifies noise. ACS counters this by dynamically scaling the random perturbations based on the same local error measurements. Specifically, if the predicted next state is too far from the current state, ACS lowers the noise level for that segment of the trajectory. This ensures that large random fluctuations are rejected when the system is already exhibiting chaotic behavior.</p>
  <p>Algorithmically, our approach proceeds as follows:</p>
  <pre><code>1. Initialize the sample x at the starting diffusion step.
2. Evaluate local error metrics by comparing one-step and multi-step predictions.
3. Scale the step size and noise factors based on thresholds.
4. Update x accordingly.
5. Repeat until the final diffusion step.
</code></pre>
  <p>In contrast to the baseline, ACS does not require iterative inversion of a fixed-point equation, nor does it hinge on harmonic expansions that may be invalid under severe guidance shifts. Each stage is governed by straightforward adaptivity rules similar to those found in modern SDE solvers. The outcome is a multi-stage integration that covers a broad range of guidance scenarios while paying computationally more attention to tricky regions of high curvature or extreme gradient magnitudes. The following section describes how we apply ACS in three distinct experiments to illustrate its advantages over a simpler linear or fixed-step baseline.</p>
</section>

<section>
  <h2>Experimental Setup</h2>
  <p>We conducted three experiments—in Python with open-source libraries—that systematically compare ACS to a baseline solver using fixed-step or fixed-noise corrections.</p>
  <p><strong>Experiment 1 (Synthetic Diffusion Trajectories):</strong> A simple ODE with known nonlinear behavior was constructed. The baseline uses a fixed-step Euler integrator, while ACS implements an adaptive step integrator comparing full and half-step updates for local error estimation. We measure iteration counts and total runtime. Even for this small system, large changes in local curvature highlight the benefits of ACS.</p>
  <p><strong>Experiment 2 (Controlled Random Perturbations in SDE Integration):</strong> An Ornstein–Uhlenbeck-like process was introduced, adding random noise through Euler–Maruyama integration. The baseline keeps a fixed noise scale. ACS, on the other hand, cues off a threshold that, if exceeded, halves the current noise scale. This results in reduced variance in the final trajectories and an improved ability to recover from artificially induced shocks.</p>
  <p><strong>Experiment 3 (End-to-End Diffusion Sampling):</strong> ACS was integrated into a toy diffusion model with a simplified UNet architecture, following a DDIM-like sampling procedure. The baseline uses uniform step sizes and noise levels, while ACS adaptively modifies step size based on the magnitude of predicted corrections. We plot the L2 norm of changes at each step to visualize convergence speed and compare final sample quality.</p>
  <p>Implementation details: Experiments 1 and 2 rely on relatively small Python scripts using NumPy, SciPy, and PyTorch for vectorized operations. Experiment 3 uses an elaborate PyTorch pipeline to simulate a simplified UNet. In all cases, iteration counts, runtime, and error metrics were recorded. The nominal hyperparameters for step sizes, noise scales, and tolerances appear in the code. While large-scale image benchmarks were not the focus, these experiments confirm the conceptual improvements ACS provides in capturing nonlinear drifts and stabilizing sample trajectories.</p>
</section>

<section>
  <h2>Results</h2>
  <p>The outcome of our comparative experiments is presented below, supported by six figures that illustrate key performance improvements of ACS.</p>
  <p><strong>Experiment 1 (Synthetic Diffusion Trajectories):</strong> ACS’s adaptive-step integrator needed far fewer iteration steps compared to the baseline. The adaptive approach precisely allocates more steps in regions of high curvature, resulting in a substantial decrease in iteration count and runtime with negligible drop in accuracy.</p>
  <figure>
    <img src="images/synthetic_diffusion_trajectory.png" style="width:70%;height:auto" alt="Synthetic Diffusion Trajectories">
    <figcaption>Figure 1: Synthetic Diffusion Trajectories showing the adaptive solver converging faster than the fixed-step method.</figcaption>
  </figure>
  <p><strong>Experiment 2 (Controlled Random Perturbations):</strong> In modeling an Ornstein–Uhlenbeck-like SDE, while the baseline used a fixed noise scale, ACS adaptively reduced the noise intensity if an update exceeded a preset error threshold. This adaptation resulted in tighter trajectories and more stable outcomes.</p>
  <figure>
    <img src="images/sde_integration_controlled.png" style="width:70%;height:auto" alt="SDE Integration with Controlled Random Perturbations">
    <figcaption>Figure 2: SDE Integration with Controlled Random Perturbations demonstrating that ACS yields more stable trajectories.</figcaption>
  </figure>
  <p><strong>Experiment 3 (End-to-End Diffusion Sampling):</strong> A basic DDIM-like sampler was implemented with and without adaptive integration. The baseline approach showed sporadic spikes in the L2 norm of step-to-step updates, whereas ACS maintained smoother convergence. Visual comparisons of final reconstructions further attest to ACS's controlled sampling under high guidance.</p>
  <figure>
    <img src="images/error_trajectory_base.png" style="width:70%;height:auto" alt="Base Method Error Trajectory">
    <figcaption>Figure 3: Base Method Error Trajectory displaying step-wise L2 norm fluctuations in fixed-step sampling.</figcaption>
  </figure>
  <figure>
    <img src="images/error_trajectory_acs.png" style="width:70%;height:auto" alt="ACS Method Error Trajectory">
    <figcaption>Figure 4: ACS Method Error Trajectory showing smoother convergence with adaptive step sizing.</figcaption>
  </figure>
  <figure>
    <img src="images/final_sample_base.png" style="width:70%;height:auto" alt="Base Method Final Sample">
    <figcaption>Figure 5: Base Method Final Sample generated using uniform steps.</figcaption>
  </figure>
  <figure>
    <img src="images/final_sample_acs.png" style="width:70%;height:auto" alt="ACS Final Sample">
    <figcaption>Figure 6: ACS Final Sample produced by adaptive modulation of step size and noise, maintaining stability under high guidance.</figcaption>
  </figure>
  <p>Overall, while the differences in computational time were modest for smaller tasks, the adaptive nature of ACS is anticipated to offer significant gains in efficiency and numerical stability for larger-scale problems or highly nonlinear guidance regimes.</p>
</section>

<section>
  <h2>Conclusions</h2>
  <p>In this paper, we presented Adaptive Characteristic Simulation (ACS) as a novel method for handling large-scale guidance within classifier-free diffusion models. By reframing the correction step as a locally adaptive SDE process rather than a fixed-point iteration, ACS gains the flexibility necessary to respond to rapidly changing gradient landscapes and large drifts that standard linear or harmonic-based methods struggle to address.</p>
  <p>Our experiments—from a synthetic ODE problem to a toy diffusion modeling scenario—demonstrate that ACS can significantly reduce iteration counts and variance in the diffusion trajectory. While the improvements were most pronounced on controlled synthetic tasks, the underlying adaptivity principles are scalable to high-dimensional datasets by concentrating computational effort where it is most needed and preventing runaway sampling in unstable regions.</p>
  <p>Future work can explore specialized error estimators, advanced step size scheduling rules, and extended forms of noise control that incorporate domain knowledge. Alternative evaluation metrics beyond classical measures may also be more appropriate for capturing the nuanced dynamics of large guidance in distributed sampling. Ultimately, by blending robust numerical methods with the objectives of guided diffusion, ACS offers a practical and modular approach for achieving a better balance between efficiency and sample quality under strong, nonlinear guidance regimes.</p>
</section>
</body>
</html>